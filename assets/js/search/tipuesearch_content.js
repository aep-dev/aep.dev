var tipuesearch = {'pages': [
{
    'title': "AIP Purpose and Guidelines",
    'text': "AIP Purpose and Guidelines Service APIs on the Internet continue to proliferate; having a machine-readable API is an expectation and prerequisite to adoption for many services. By some estimates, there are now more than 20,000 public REST APIs available. As this corpus continues to grow, many companies struggle with API Governance: even as companies grow and disparate teams work to deliver discrete services, APIs ought to remain simple, intuitive, and consistent. Therefore, it is increasingly necessary to have a corpus of documentation for API producers, reviewers, and other interested parties to reference. The AIP collection provides a way to provide consistent documentation for API design guidance. What is an AIP? AIP stands for API Improvement Proposal, which is a design document providing high-level, concise documentation for API development. Companies that adopt the AIP program use them as a source of truth for API-related documentation, and the means by which service producers discuss and come to consensus on API guidance. AIPs are maintained as Markdown files with metadata in the AIP GitHub repository. Adopting AIPs Companies may adopt the AIP system in one of two ways: By applying the guidance described at aip.dev. By \"forking\" the AIP system and setting up their own subdomain. Companies with an already-established corpus of services are unlikely to have exactly followed the guidance at aip.dev. Forking the system is valuable because the guidance becomes comparable. Forks must retain the same numbering system (AIP-2) to provide that comparability. Technical leadership The AIP system, as well as the guidance on aip.dev, is overseen by the AIP technical steering committee. The committee is the set of people who make decisions on AIPs. The general goal is that the AIP process is collaborative and that we largely work on the basis of consensus. However, a limited number of designated approvers is necessary, and these committee members will be approvers for each AIP on aip.dev. The technical steering committee membership is currently: Antoine Boyer (@tinnou), Netflix Ross Hamilton (@rhamiltonsf), Salesforce Mike Kistler (@mkistler), IBM Luke Sneeringer (@lukesneeringer), Google The committee is also responsible for the administrative and editorial aspects of shepherding AIPs and managing the AIP pipeline and workflow. They approve PRs to AIPs, assign proposal numbers, manage the agenda, set AIP states, and so forth. They also ensure that AIPs are readable (proper spelling, grammar, sentence structure, markup, etc.). Committee membership is by invitation of the current committee. The committee must not include more than two members from the same company. Note: Companies that maintain their own fork of aip.dev select their own leadership and have full control of their fork\u0027s content. States At any given time, AIPs may exist in a variety of states as they work their way through the process. The following is a summary of each state. Reviewing Initial discussion on most AIPs occurs in the initial pull request to submit the AIP. Once this PR is merged, the AIP exists in the \"Reviewing\" state. This means that the authors and the technical steering committee have reached a general consensus on the proposal. At this stage, the committee may request changes or suggest alternatives to the proposal before moving forward, but there is a general expectation that the proposal will move forward and it is usually safe to \"early adopt\" it. An AIP must be in the reviewing state for at least 14 days before being approved, and the committee should send appropriate communication regarding the pending approval. Note: As a formal matter, one AIP approver (other than the author) must provide formal signoff to advance an AIP to the reviewing state. Additionally, there must not be formal objections (\"changes requested\" on the GitHub PR) from other approvers. Approved Once an AIP has been agreed upon, it enters \"approved\" state and is considered \"best current practice\". AIPs may be edited after they are approved, either to correct grammar or word choices, or to clarify semantic guidance (in response to reader questions). In rare occasions, new guidance may be added. Clarifications and new guidance must be reflected in the changelog. Correction of typos or minor language alterations may be done silently. Note: As a formal matter, two AIP approvers (other than the author) must provide formal signoff to advance an AIP to the approved state. Additionally, there must not be formal objections (\"changes requested\" on the GitHub PR) from other approvers. Final If an AIP has been approved for a significant period and the technical steering committee is certain that no further guidance will be needed, they may move the AIP in to \"final\" state. AIPs in the final state must not be amended with new guidance. They may be editied to correct spelling, grammar, or clarity provided there are no semantic changes. Note: As a formal matter, two AIP approvers must provide formal signoff to advance an AIP to the final state. Additionally, there must not be formal objections (\"changes requested\" on the GItHub PR) from other approvers. Replaced If an AIP has been replaced by another AIP, it enters \"replaced\" state. The AIP must include a notice explaining the replacement and rationale (the replacement AIP should also clearly explain the rationale). In general, service producers rely primarily on AIPs in the \"approved\" state. Service producers may rely on AIPs in the \"reviewing\" state Withdrawn If an AIP is withdrawn by the author or champion, or is rejected by the technical steering committee after reaching the \"reviewing\" state, it enters \"withdrawn\" state. Withdrawn AIPs remain accessible, but are removed from the indexes; they provide documentation and reference to inform future discussions. Workflow The following workflow describes the process for proposing an AIP, and moving an AIP from proposal to implementation to final acceptance. Overview digraph d_front_back { rankdir=LR; node [ style=\"filled,solid\" shape=box fontname=\"Roboto\" ]; github_pr [ shape=\"oval\" label=\"GitHub PR\" fillcolor=\"orange\" ]; reviewing [ label=\"Reviewing\" fillcolor=\"lightskyblue\" ]; approved [ label=\"Approved\" fillcolor=\"palegreen\" ]; final [ label=\"Final\" fillcolor=\"palegreen\" ]; withdrawn [ label=\"Withdrawn\" fillcolor=\"mistyrose\" ]; replaced [ label=\"Replaced\" fillcolor=\"lightsteelblue\" ]; github_pr -\u003e reviewing; reviewing -\u003e approved; reviewing -\u003e withdrawn [ style=dashed, color=mistyrose3 ]; approved -\u003e final; approved -\u003e replaced [ style=dashed, color=lightsteelblue3 ]; final -\u003e replaced [ style=dashed color=lightsteelblue3 ]; } Proposing an AIP In order to propose an AIP, first open a pull request with a draft AIP; the AIP should conform to the guidance in AIP-8. Most AIPs should be no more than two pages if printed out. If the technical steering committee has suggested an AIP number, use that; otherwise use 99 (and expect to change it during the course of the review). Important: Ensure that the PR is editable by maintainers. In most circumstances, the committee will assign the proposal an AIP number and begin discussion. Once there is consensus, the committee will merge the PR, and the AIP will enter the \"reviewing\" state. The committee may reject an AIP outright if they have an obvious reason to do so (e.g. the proposal was already discussed and rejected in another AIP or is fundamentally unsound), in which case the PR is not merged. Accepting an AIP The editors will work together to ensure that qualified proposals do not linger in review. To gain final approval, an AIP must be approved by, at minimum, two members of the technical steering committee. Additionally, there should not be any committee members requesting significant changes (indicated by the use of the \"changes requested\" feature on GitHub). Note: If an AIP editor is the primary author of an AIP, then at least two other editors must approve it. Withdrawing or Rejecting an AIP The author of an AIP may decide, after further consideration, that an AIP should not advance. If so, the author may withdraw the AIP by updating the PR adding a notice of withdrawal with an explanation of the rationale. Additionally, the author may be unable to get consensus among the group and the technical steering committee may elect to reject the AIP. In this situation, the committee shall amend the PR adding a notice of rejection with an explanation of the rationale. In both cases, the committee must update the state accordingly and submit the PR. Replacing an AIP In rare cases, it may be necessary to replace an AIP with another one. This is not general practice: minor edits to approved AIPs are acceptable, and AIPs only enter final state when there is high confidence that further edits will not be necessary. However, if new guidance fundamentally alters the old guidance in some way, then the technical steering committee should create a new AIP that, once approved, will replace the old one. The old one then enters \"Replaced\" state, and will link to the new, current AIP.",
    'tags': '',
    'url': '/aip.dev/1',
  },
{
    'title': "Enumerations",
    'text': "Enumerations It is common for a field to only accept or provide a discrete and limited set of values. In these cases, it can be useful to use enumerations (generally abbreviated \"enums\") in order to clearly communicate what the set of allowed values are. Guidance APIs may expose enum objects for sets of values that are expected to change infrequently: // Possible formats in which a book may be published. enum Format { // The printed format, in hardback. Hardback = \u0027HARDBACK\u0027, // The printed format, in paperback. Paperback = \u0027PAPERBACK\u0027, // An electronic book format. Ebook = \u0027EBOOK\u0027, // An audio recording. Audiobook = \u0027AUDIOBOOK\u0027, } All enum values should use a consistent case format across an organization. In many cases, this is dictated by the IDL the organization uses. Enums should document whether the enum is frozen or they expect to add values in the future. When to use enums Enums can be more accessible and readable than strings or booleans in many cases, but they do add overhead when they change. Therefore, enums should receive new values infrequently. While the definition of \"infrequently\" may change based on individual use cases, a good rule of thumb is no more than once a year. For enums that change frequently, the API should use a string and document the format. Note: If an enumerated value needs to be shared across APIs, an enum may be used, but the assignment between enum values and their wire representation must match. Alternatives Enums should not be used when there is a competing, widely-adopted standard representation (such as with language codes or media types). Instead, that standard representation should be used. This is true even if only a small subset of values are permitted, because using enums in this situation often leads to frustrating lookup tables when trying to use multiple APIs together. For enumerated values where the set of allowed values changes frequently, APIs should use a string field instead, and must document the allowed values. String fields with enumerated values should use a uniform case system (snake_case, kebab-case, etc.) throughout an organization. Boolean fields may be used in situations where it is clear that no further flexibility will be needed. The default value must be false. Compatibility Adding values to an enum has the potential to be disruptive to existing clients. Consider code written against the Format enum in an earlier version where only the first two options were available: switch (book.format) { case Format.Hardback: // Do something... break; case Format.Paperback: // Do something... break; default: // When new enum values are introduced, pre-existing client code may // throw errors or act in unexpected ways. throw new Error(\u0027Unrecognized value.\u0027); } Services may add new values to existing enums; however, they should add enums carefully; think about what will happen if a client system does not know about a new value. Additionally, in IDLs where enum values are presented in a specific order, services should only add new values to the end. An exception to this rule is if the enum conforms to an external standard (for example, an enum representing HTTP status codes would add a new 3xx value alongside the others, not at the end). Interface Definitions Protocol buffers // Possible formats in which the book may be published. enum Format { // Default value. This value is unused. FORMAT_UNSPECIFIED = 0; // The printed format, in hardback. HARDBACK = 1; // The printed format, in paperback. PAPERBACK = 2; // An electronic book format. EBOOK = 3; // An audio recording. AUDIOBOOK = 4; } The zero value of the enum should be the name of the enum itself followed by the suffix _UNSPECIFIED. The service may either allow or prohibit use of this value. Enums which will only be used in a single message should be nested within that message. In this case, the enum should be declared immediately before it is used. If multiple enums are in the same namespace, they must not share any values. (This is because enums do not provide their own namespace for their values in some languages.) If an enumerated value needs to be shared across APIs, an enum may be used, but the assignment between the value names and the tag numbers must match. Note: When using protocol buffers, it is impossible to distinguish between false and unset. If this is a requirement, an enum may be a better design choice (although google.protobuf.BoolValue is also available). OpenAPI 3.0 format: type: string description: The format of the book. nullable: true enum: - null - HARDCOVER - PAPERBACK - EBOOK - AUDIOBOOK Enumerated fields should be strings. If the enum is optional, The null value should be used as the empty value, and should be the first value specified. Note: If null is a valid value, OpenAPI 3.0 also requires that nullable: true is specified for the field. Further reading For states, a special type of enum, see AIP-216.",
    'tags': '',
    'url': '/aip.dev/126',
  },
{
    'title': "GET for individual resources",
    'text': "GET for individual resources In REST APIs, it is customary to make a GET request to a resource\u0027s URI (for example, /v1/publishers/{publisher}/books/{book}) in order to retrieve that resource. Our APIs honor this pattern by allowing GET requests to be sent to the resource URI, which returns the resource itself. Guidance APIs should generally provide a GET method for resources unless it is not valuable for users to do so. When the GET method is used on a URI ending in a resource ID or resource ID alias, the result should be a single resource. For more information about using the GET method on a URI ending with a resource collection identifier, see AIP-132. Requests Single-resource GET operations must be made by sending a GET request to the resource\u0027s URI: GET /v1/publishers/{publisher}/books/{book} HTTP/2 Host: library.googleapis.com Accept: application/json The HTTP method must be GET. The request must be safe and must not have side effects. There must not be a request body. If a GET request contains a body, the body must be ignored, and must not cause an error. The request must not require any fields in the query string. The request should not include optional fields in the query string unless described in another AIP. Responses Single-resource GET operations must return the resource itself, without any additional wrapping: { \"name\": \"publishers/lacroix/books/les-mis\", \"isbn\": \"978-037-540317-0\", \"title\": \"Les Mis\u00e9rables\", \"authors\": [\"Victor Hugo\"], \"rating\": 9.6 } Errors If the user does not have sufficient permission to know that the resource exists, the service should reply with an HTTP 404 error, regardless of whether or not the resource exists. Permission must be checked prior to checking if the resource exists. If the user has sufficient permission to know that the resource exists, but is unable to access it, the service should reply with an HTTP 403 error. If the user does have proper permission, but the requested resource does not exist, the service must reply with an HTTP 404 error. Interface Definitions Protocol buffers Get operations are specified using the following pattern: // Get a single book. rpc GetBook(GetBookRequest) returns (Book) { option (google.api.http) = { get: \"/v1/{name=publishers/*/books/*}\" }; option (google.api.method_signature) = \"name\"; } The RPC\u0027s name must begin with the word Get. The remainder of the RPC name should be the singular form of the resource\u0027s message name. The request message must match the RPC name, with a -Request suffix. The response message must be the resource itself. (There is no GetBookResponse.) The response should usually include the fully-populated resource unless there is a reason to return a partial response (see AIP-157). The HTTP verb must be GET. The URI should contain a single variable field corresponding to the resource name. This field should be called name. The URI should have a variable corresponding to this field. The name field should be the only variable in the URI path. All remaining parameters should map to URI query parameters. There must not be a body key in the google.api.http annotation. There should be exactly one google.api.method_signature annotation, with a value of \"name\". Get operations also implement a common request message pattern: // Request message to get a single book. message GetBookRequest { // The name of the book to retrieve. string name = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { type: \"library.googleapis.com/Book\" }]; } A resource name field must be included. It should be called name. The field should be annotated as required. The field should identify the resource type that it references. The comment for the name field should document the resource pattern. The request message must not contain any other required fields, and should not contain other optional fields except those described in another AIP. Note: The name field in the request object corresponds to the name variable in the google.api.http annotation on the RPC. This causes the name field in the request to be populated based on the value in the URL when the REST/JSON interface is used. OpenAPI 3.0 Single-resource GET operations must be specified with consistent OpenAPI metadata: paths: /publishers/{publisherId}/books/{bookId}: get: operationId: getBook description: Get a single book. responses: 200: description: OK content: application/json: schema: $ref: \u0027#/components/schemas/Book\u0027 The operationId must begin with the word get. The remainder of the operationId should be the singular form of the resource type\u0027s name. The response content must be the resource itself. For example: #/components/schemas/Book The response should usually include the fully-populated resource unless there is a reason to return a partial response (see AIP-157). The URI should contain a variable for each individual ID in the resource hierarchy. The path parameter for all resource IDs must be in the form {resourceName}Id (such as bookId), and path parameters representing the ID of parent resources must end with Id.",
    'tags': '',
    'url': '/aip.dev/131',
  },
{
    'title': "Array fields",
    'text': "Array fields Representing lists of data in an API is trickier than it often appears. Users often need to modify lists in place, and longer data series within a single resource pose a challenge for pagination. Guidance Resources may use array fields where appropriate. interface Book { // The resource name for the book. name: string; // The authors of the book. authors: string[]; } Array fields must use a plural field name. If the English singular and plural words are identical (\"moose\", \"info\"), the dictionary word must be used rather than attempting to coin a new plural form. Array fields should have an enforced upper bound that will not cause a single resource payload to become too large. A good rule of thumb is 100 elements. If an array data can not be bounded (in other words, if there is a chance that the array will be too large to be reasonably returned in a single request), the API should use a sub-resource instead. Array fields must not represent the body of another resource inline. Instead, the field should be a array of strings providing the resource names of the associated resources. Note: This document uses the term \"array\" to refer to a field on a resource that is a list of elements that have the same type. Some languages and IDLs use other terms, such as \"list\", \"repeated\", or \"sequence\", and these terms are all synonymous for the purposes of this document. The term \"collection\" is distinct, and refers to a group of resources under a single parent rather than a field on a resource. Scalars and structs Array fields should use a scalar type (such as string) if they are certain that additional data will not be needed in the future, as using a struct type adds significant cognitive overhead and leads to more complicated code. However, if additional data is likely to be needed in the future, array fields should use a struct instead of a scalar proactively, to avoid parallel array fields. Update strategies A resource may use one of two strategies to enable updating a array field: direct update using the standard Update method, or custom Add and Remove methods. A standard Update method has one key limitation: the user is only able to update the entire array. This means that the user is required to read the resource, make modifications to the array field value as needed, and send it back. This is fine for many situations, particularly when the array field is expected to have a small size (fewer than 10 or so) and race conditions are not an issue, or can be guarded against with ETags. Note: Declarative-friendly resources (AIP-128) must use the standard Update method, and not introduce Add and Remove methods. If declarative tools need to reason about particular relationships while ignoring others, consider using a subresource instead. If atomic modifications are required, and if the array is functionally a set (meaning that order does not matter, duplicate values are not meaningful, and non-comparable values such as null or NaN are not used), the API should define custom methods using the verbs Add and Remove: Protocol buffers // Add an author to a book. rpc AddAuthor(AddAuthorRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{book=publishers/*/books/*}:addAuthor\" body: \"*\" }; } // Remove an author from a book. rpc RemoveAuthor(RemoveAuthorRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{book=publishers/*/books/*}:removeAuthor\" body: \"*\" }; } The data being added or removed should be a primitive (usually a string). For more complex data structures with a primary key, the API should use a map with the Update method instead. The RPC\u0027s name must begin with the word Add or Remove. The remainder of the RPC name should be the singular form of the field being added. The response should be the resource itself, and should fully-populate the resource structure. The HTTP method must be POST, as usual for custom methods. The HTTP URI must end with :add* or :remove*, where * is the camel-case singular name of the field being added or removed. The request field receiving the resource name should map to the URI path. The HTTP variable should be the name of the resource (such as book) rather than name or parent. That variable should be the only variable in the URI path. The body clause in the google.api.http annotation should be \"*\". If the data being added in an Add operation is already present, the method should accept the request and make no changes (no-op), but may error with ALREADY_EXISTS if appropriate. If the data being removed in a Remove operation is not present, the method should accept the request and make no changes (no-op), but may error with NOT_FOUND if appropriate. OpenAPI 3.0 paths: \u0027/publishers/{publisherId}/books/{bookId}:addAuthor\u0027: post: operationId: addAuthor description: Add an author to a book. requestBody: content: application/json: schema: properties: author: type: string description: The author to be added. required: true required: true responses: 200: description: OK content: application/json: schema: $ref: \u0027#/components/schemas/Book\u0027 \u0027/publishers/{publisherId}/books/{bookId}:removeAuthor\u0027: post: operationId: removeAuthor description: Remove an author from a book. requestBody: content: application/json: schema: properties: author: type: string description: The author to be removed. required: true required: true responses: 200: description: OK content: application/json: schema: $ref: \u0027#/components/schemas/Book\u0027 The data being added or removed should be a primitive (usually a string). For more complex data structures with a primary key, the API should use a map with the Update method instead. The operationId must begin with the word add or remove. The remainder of the operationId should be the singular form of the field being added. The response should be the resource itself, and should fully-populate the resource structure. The HTTP method must be POST, as usual for custom methods. The HTTP URI must end with :add* or :remove*, where * is the camel-case singular name of the field being added or removed. If the data being added in an Add operation is already present, the method should accept the request and make no changes (no-op), but may error with 409 Conflict if appropriate. If the data being removed in a Remove operation is not present, the method should accept the request and make no changes (no-op), but may error with 404 Not Found if appropriate. Note: If both of these strategies are too restrictive, consider using a subresource instead. Request Structure Protocol buffers // The request structure for the AddAuthor operation. message AddAuthorRequest { // The name of the book to add an author to. string book = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference).type = \"library.googleapis.com/Book\" ]; // The author to be added. string author = 2 [(google.api.field_behavior) = REQUIRED]; } // The request structure for the RemoveAuthor operation. message RemoveAuthorRequest { // The name of the book to remove an author from. string book = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference).type = \"library.googleapis.com/Book\" ]; // The author to be removed. string author = 2 [(google.api.field_behavior) = REQUIRED]; } A resource field must be included. It should be the name of the resource (such as book) rather than name or parent. The field should be annotated as required. If the field represents the name of another resource, it should identify the resource type that it references. A field for the value being added or removed must be included. It should be the singular name of the field. The field should be annotated as required. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. OpenAPI 3.0 requestBody: content: application/json: schema: properties: author: type: string description: The author to be added. required: true required: true A field for the value being added or removed must be included. It should be the singular name of the field. The field should be designated as required.",
    'tags': '',
    'url': '/aip.dev/144',
  },
{
    'title': "Ranges",
    'text': "Ranges Services often need to represent ranges of discrete or continuous values. These have wide differences in meaning, and come in many types: integers, floats, and timestamps, just to name a few, and the expected meaning of a range can vary in subtle ways depending on the type of range being discussed. Guidance A resource or message representing a range should ordinarily use two separate fields of the same type, with prefixes start_ and end_: // A representation of a chapter in a book. interface Chapter { title: string; // The page where this chapter begins. startPage: number; // The page where the next chapter or section begins. endPage: number; } Inclusive or exclusive ranges Fields representing ranges should use inclusive start values and exclusive end values (half-closed intervals) in most situations; in interval notation: [start_xxx, end_xxx). Exclusive end values are preferable for the following reasons: It conforms to user expectations, particularly for continuous values such as timestamps, and avoids the need to express imprecise \"limit values\" (e.g. 2012-04-20T23:59:59). It is consistent with most common programming languages, including C++, Java, Python, and Go. It is easier to reason about abutting ranges: [0, x), [x, y), [y, z), where values are chainable from one range to the next. Exceptions In some cases, there is significant colloquial precedent for inclusive start and end values (closed intervals), to the point that using an exclusive end value would be confusing even for people accustomed to them. For example, when discussing dates (not to be confused with timestamps), most people use inclusive end: a conference with dates \"April 21-23\" is expected to run for three days: April 21, April 22, and April 23. This is also true for days of the week: a business that is open \"Monday through Friday\" is open, not closed, on Fridays. In this situation, the prefixes first and last should be used instead: // A representation of a chapter in a book. interface Chapter { title: string; // The first page of the chapter. firstPage: number; // The last page of the chapter. lastPage: number; } Fields representing ranges with significant colloquial precedent for inclusive start and end values should use inclusive end values with first_ and last_ prefixes for those ranges only. The service should still use exclusive end values for other ranges where this does not apply, and must clearly document each range as inclusive or exclusive.",
    'tags': '',
    'url': '/aip.dev/145',
  },
{
    'title': "Long-running requests",
    'text': "Long-running requests Occasionally, a service may need to expose an operation that takes a significant amount of time to complete. In these situations, it is often a poor user experience to simply block while the task runs; rather, it is better to return some kind of promise to the user, and allow the user to check back in later. The long-running request pattern is roughly analogous to a Future in Python or Java, or a Node.js Promise. Essentially, the user is given a token that can be used to track progress and retrieve the result. Guidance Operations that might take a significant amount of time to complete should return a 202 Accepted response along with an identifier that can be used to track the status of the request and ultimately retrieve the result. Any single operation defined in an API surface must either always return 202 Accepted along with a request identifier, or never do so. A service must not return a 200 OK response with the result if it is \"fast enough\", and 202 Accepted if it is not fast enough, because such behavior adds significant burdens for clients. Note: User expectations can vary on what is considered \"a significant amount of time\" depending on what work is being done. A good rule of thumb is 10 seconds. Status monitor representation The response to a long-running request should be a \"status monitor\" having the following common format: interface StatusMonitor { // The identifier for this status monitor. id: string; // Whether the request is done. done: boolean; // The result of the request. // Only populated if the request is done and was successful. response: any; // The error that arose from the request. // Only populated if the request is done and was unsuccessful. error: Error; // Metadata associated with the request. // Populated throughout the life of the request, including after // it completes. metadata: any; } If the done field is true, then one and exactly one of the response and error fields must be populated. If the done field is false, then the response and error fields must not be populated. The response and metadata fields may be any type that the service determines to be appropriate, but must always be the same type for any particular operation. The response and metadata types should be defined in the same API surface as the operation itself. The response and metadata types that need no data should use a custom-defined empty struct rather than a common void or empty type, to permit future extensibility. Querying a status monitor The service must provide an endpoint to query the status of the operation, which must accept the operation identifier and should not include other parameters: GET /v1/statusMonitors/{status_monitor} HTTP/2 Host: library.googleapis.com Accept: application/json The endpoint must return a StatusMonitor as described above. Standard methods APIs may return an StatusMonitor from the Create, Update, or Delete standard methods if appropriate. In this case, the response field must be the standard and expected response type for that standard method. When creating or deleting a resource with a long-running request, the resource should be included in List and Get calls; however, the resource should indicate that it is not usable, generally with a state enum. Parallel requests A resource may accept multiple requests that will work on it in parallel, but is not obligated to do so: Resources that accept multiple parallel requests may place them in a queue rather than work on the requests simultaneously. Resource that does not permit multiple requests in parallel (denying any new request until the one that is in progress finishes) must return 409 Conflict if a user attempts a parallel request, and include an error message explaining the situation. Expiration APIs may allow their status monitor resources to expire after sufficient time has elapsed after the request completed. Note: A good rule of thumb for status monitor expiry is 30 days. Errors Errors that prevent a long-running request from starting must return an error response (AIP-193), similar to any other method. Errors that occur over the course of a request may be placed in the metadata message. The errors themselves must still be represented with a canonical error object. Interface Definitions Protocol buffers When using protocol buffers, the well-known type google.longrunning.Operation is used. Note: For historical reasons, Google uses the term Operation to represent what this document describes as a StatusMonitor. // Write a book. rpc WriteBook(WriteBookRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:write\" body: \"*\" }; option (google.longrunning.operation_info) = { response_type: \"WriteBookResponse\" metadata_type: \"WriteBookMetadata\" }; } The response type must be google.longrunning.Operation. The Operation proto definition must not be copied into individual APIs. The response must not be a streaming response. The method must include a google.longrunning.operation_info annotation, which must define both response and metadata types. The response and metadata types must be defined in the file where the RPC appears, or a file imported by that file. If the response and metadata types are defined in another package, the fully-qualified message name must be used. The response type should not be google.protobuf.Empty (except for Delete methods), unless it is certain that response data will never be needed. If response data might be added in the future, define an empty message for the RPC response and use that. The metadata type is used to provide information such as progress, partial failures, and similar information on each GetOperation call. The metadata type should not be google.protobuf.Empty, unless it is certain that metadata will never be needed. If metadata might be added in the future, define an empty message for the RPC metadata and use that. APIs with messages that return Operation must implement the Operations service. Individual APIs must not define their own interfaces for long-running operations to avoid inconsistency. OpenAPI 3.0 paths: /v1/resources: post: operationId: write_book description: Write a book. responses: 202: description: OK content: application/json: schema: $ref: \u0027#/components/schemas/WriteBookStatus\u0027 202 must be the only success status code defined. The 202 response must define an application/json response body and no other response content types. The response body schema must be an object with name, done, and result properties as described above for a StatusMonitor The response body schema may contain an object property named metadata to hold service-specific metadata associated with the operation, for example progress information and common metadata such as create time. The service should define the contents of the metadata object in a separate schema, which should specify additionalProperties: true to allow for future extensibility. The response property must be a schema that defines the success response for the operation. For an operation that typically gives a 204 No Content response, such as a Delete, response should be defined as an empty object schema. For a standard Get/Create/Update operation, response should be a representation of the resource. If a service has any long running operations, the service must define an StatusMonitor resource with a list operation to retrieve a potentially filtered list of status monitors and a get operation to retrieve a specific status monitor by its name.",
    'tags': '',
    'url': '/aip.dev/151',
  },
{
    'title': "Resource freshness validation",
    'text': "Resource freshness validation APIs often need to validate that a client and server agree on the current state of a resource before taking some kind of action on that resource. For example, two processes updating the same resource in parallel could create a race condition, where the latter process \"stomps over\" the effort of the former one. ETags provide a way to deal with this, by allowing the server to send a checksum based on the current content of a resource; when the client sends that checksum back, the server can ensure that the checksums match before acting on the request. Guidance A resource may provide an ETag header when retrieving a single resource when it is important to ensure that the client has an up to date resource before acting on certain requests: 200 OK Content-type: application/json ETag: \"55cc0347-66fc-46c3-a26f-98a9a7d61d0e\" The ETag must be provided by the server on output, and values should conform to RFC 7232. Resources must support the If-Match header (and may support the If-None-Match header) if and only if resources provide the ETag. Note: ETag values must include quotes as described in RFC 7232. For example, a valid ETag is \"foo\", not foo. ETags must be based on an opaque checksum or hash of the resource that guarantees it will change if the resource changes. Condition headers Services that provide ETags should support the If-Match and If-None-Match headers on incoming requests: GET /v1/publishers/{publisher}/books/{book} HTTP/2 Host: library.googleapis.com Accept: application/json If-Match: \"55cc0347-66fc-46c3-a26f-98a9a7d61d0e\" If the service receives a request to modify a resource that includes an If-Match header, the service must validate that the value matches the current ETag. If the If-Match header value does not match the ETag, the service must reply with an HTTP 412 error. If the user omits the If-Match header, the service should permit the request. However, services with strong consistency or parallelism requirements may require users to send ETags all the time and reject the request with an HTTP 400 error if it does not contain an ETag. If any conditional headers are supported for any operation within a service, the same conditional headers must be supported for all mutation methods (POST, PATCH, PUT, and DELETE) of any path that supports them, and should be supported uniformly for all operations across the service. If any validator or conditional headers are supported for any operations in the service, the use of unsupported conditional headers must result in an error. (In other words, once a service gives the client reason to believe it understands conditional headers, it must not ever ignore them.) Read requests If a service receives a GET or HEAD request with an If-Match header, the service must proceed with the request if the ETag matches, or send a 412 Precondition Failed error if the ETag does not match. If a service receives a GET or HEAD request with an If-None-Match header, the service must proceed with the request if the ETag does not match, or return a 304 Not Modified response if the ETag does match. Strong and weak ETags ETags can be either \"strongly validated\" or \"weakly validated\": A strongly validated ETag means that two resources bearing the same ETag are byte-for-byte identical. A weakly validated ETag means that two resources bearing the same ETag are equivalent, but may differ in ways that the service does not consider to be important. Resources may use either strong or weak ETags, as it sees fit, but should document the behavior. Additionally, weak ETags must have a W/ prefix as mandated by RFC 7232: 200 OK Content-type: application/json ETag: W/\"55cc0347-66fc-46c3-a26f-98a9a7d61d0e\" Strong ETags must and weak ETags should be guaranteed to change if any properties on the resource change that are directly mutable by the client. Additionally, strong ETags should be guaranteed to change if the resource\u0027s representation changes in a meaningful way (meaning the new representation is not equivalent to the old one). Further reading For how to retry on errors in client libraries, see AIP-194. Changelog 2020-09-02: Clarified that other errors may take precedence over FAILED_PRECONDITION for ETag mismatches. 2020-09-02: Add guidance for ETags on request messages. 2019-09-23: Changed the title to \"resource freshness validation\".",
    'tags': '',
    'url': '/aip.dev/154',
  },
{
    'title': "Pagination",
    'text': "Pagination APIs often need to provide collections of data, most commonly in the List standard method. However, collections can often be arbitrarily sized, and also often grow over time, increasing lookup time as well as the size of the responses being sent over the wire. Therefore, it is important that collections be paginated. Guidance Operations returning collections of data must provide pagination at the outset, as it is a backwards-incompatible change to add pagination to an existing method. // The request structure for listing books. interface ListBooksRequest { // The parent, which owns this collection of books. // Format: publishers/{publisher} parent: string; // The maximum number of books to return. The service may return fewer than // this value. // If unspecified, at most 50 books will be returned. // The maximum value is 1000; values above 1000 will be coerced to 1000. maxPageSize: bigint; // A page token, received from a previous `ListBooks` call. // Provide this to retrieve the subsequent page. // // When paginating, all other parameters provided to `ListBooks` must match // the call that provided the page token. pageToken: string; } // The response structure from listing books. interface ListBooksResponse { // The books from the specified publisher. books: Book[]; // A token that can be sent as `page_token` to retrieve the next page. // If this field is omitted, there are no subsequent pages. nextPageToken: string; } Request definitions for collections should define an int32 max_page_size field, allowing users to specify the maximum number of results to return. If the user does not specify max_page_size (or specifies 0), the API chooses an appropriate default, which the API should document. The API must not return an error. If the user specifies max_page_size greater than the maximum permitted by the service, the service should coerce down to the maximum permitted page size. If the user specifies a negative value for max_page_size, the API must return a 400 Bad Request error. The service should the number of results requested, unless the end of the collection is reached. However, occasionally this is infeasible, especially within expected time limits. In these cases, the service may return fewer results than the number requested (including zero results), even if not at the end of the collection. Request definitions for collections should define a string page_token field, allowing users to advance to the next page in the collection. If the user changes the max_page_size in a request for subsequent pages, the service must honor the new page size. The user is expected to keep all other arguments to the operation request the same; if any arguments are different, the API should send a 400 Bad Request error. The response must not be a streaming response. Services may support using page tokens across versions of a service, but are not required to do so. Response definitions for collections must define a string next_page_token field, providing the user with a page token that may be used to retrieve the next page. The field containing pagination results should be the first field specified. It should be a repeated field containing a list of resources constituting a single page of results. If the end of the collection has been reached, the next_page_token field must be empty. This is the only way to communicate \"end-of-collection\" to users. If the end of the collection has not been reached (or if the API can not determine in time), the service must provide a next_page_token. Response definitions may include a string next_page_url field containing the full URL for the next page. Response definitions for collections may provide an int32 total_size field, providing the user with the total number of items in the list. This total may be an estimate (but the API should explicitly document that). Skipping results The request definition for a paginatied operation may define an int32 skip field to allow the user to skip results. The skip value must refer to the number of individual resources to skip, not the number of pages. For example: A request with no page token and a skip value of 30 returns a single page of results starting with the 31st result. A request with a page token corresponding to the 51st result (because the first 50 results were returned on the first page) and a skip value of 30 returns a single page of results starting with the 81st result. If a skip value is provided that causes the cursor to move past the end of the collection of results, the response must be 200 OK with an empty result set, and not provide a next_page_token. Opacity Page tokens provided by services must be opaque (but URL-safe) strings, and must not be user-parseable. This is because if users are able to deconstruct these, they will do so. This effectively makes the implementation details of your API\u0027s pagination become part of the API surface, and it becomes impossible to update those details without breaking users. Warning: Base-64 encoding an otherwise-transparent page token is not a sufficient obfuscation mechanism. For page tokens which do not need to be stored in a database, and which do not contain sensitive data, an API may obfuscate the page token by defining an internal protocol buffer message with any data needed, and send the serialized proto, base-64 encoded. Page tokens must be limited to providing an indication of where to continue the pagination process only. They must not provide any form of authorization to the underlying resources, and authorization must be performed on the request as with any other regardless of the presence of a page token. Expiring page tokens Many services store page tokens in a database internally. In this situation, the service may expire page tokens a reasonable time after they have been sent, in order not to needlessly store large amounts of data that is unlikely to be used. It is not necessary to document this behavior. Note: While a reasonable time may vary between services, a good rule of thumb is three days. Consistency When discussing pagination, consistency refers to the question of what to do if the underlying collection is modified while pagination is in progress. The most common way that this occurs is for a resource to be added or deleted in a place that the pagination cursor has already passed. Services may choose to be strongly consistent by approximating the \"repeatable read\" behavior in databases, and returning exactly the records that exist at the time that pagination begins. Backwards compatibility Adding pagination to an existing operation is a backwards-incompatible change. This may seem strange; adding fields to interface definitions is generally backwards compatible. However, this change is behaviorally incompatible. Consider a user whose collection has 75 resources, and who has already written and deployed code. If the API later adds pagination fields, and sets the default to 50, then that user\u0027s code breaks; it was getting all resources, and now is only getting the first 50 (and does not know to advance pagination). Even if the API set a higher default limit, such as 100, the user\u0027s collection could grow, and then the code would break. For this reason, it is important to always add pagination to operations returning collections up front; they are consistently important, and they can not be added later without causing problems for existing users. Warning: This also entails that, in addition to presenting the pagination fields, they must be actually implemented with a non-infinite default value. Implementing an in-memory version (which might fetch everything then paginate) is reasonable for initially-small collections. Implementation Page tokens should be versioned independently of the public API, so that page tokens can be used with any version of the service. The simplest form of a page token only requires an offset. However, offsets pose challenges when a distributed database is introduced, so a more robust page token needs to store the information needed to find a \"logical\" position in the database. The simplest way to do this is to include relevant data from the last result returned. Primarily, this means the resource ID, but also includes any other fields from the resource used to sort the results (for the event where the resource is changed or deleted). This information is from the resource itself, and therefore might be sensitive. Sensitive data must be encrypted before being used in a page token. Therefore, the token also includes the date it was created, to allow for the potential need to rotate the encryption key. This yields the following interface, which may be base64 encoded and used as a page token: interface PageTokenSecrets { // The ID of the most recent resource returned. lastId: string; // Any index data needed, generally 1:1 with the fields used for ordering. indexData: Buffer[]; // When this token was minted. createTime: Date; } Note: This section does not preclude alternative page token implementations provided they conform to the guidelines discussed in this document.",
    'tags': '',
    'url': '/aip.dev/158',
  },
{
    'title': "Unicode",
    'text': "Unicode APIs should be consistent on how they explain, limit, and bill for string values and their encodings. This ranges from little ambiguities (like fields \"limited to 1024 characters\") all the way to billing confusion (are names and values of properties in Datastore billed based on characters or bytes?). In general, if limits are measured in bytes, we are discriminating against non-ASCII text since it takes up more space. On the other hand, if limits are measured in \"characters\", this is ambiguous about whether those are Unicode \"code points\", \"code units\" for a particular encoding (e.g. UTF-8 or UTF-16), \"graphemes\", or \"grapheme clusters\". Unicode primer Character encoding tends to be an area we often gloss over, so a quick primer: Strings are just sequences of bytes that represent text according to some encoding format. When we talk about characters, we sometimes mean Unicode code points, which are 21-bit unsigned integers 0 through 0x10FFFF. Other times we might mean grapheme clusters, which are perceived as single characters but may be composed of multiple code points. For example, \u00e1 can be represented as the single code point U+00E1 or as a sequence of U+0061 followed by U+0301 (the letter a, then a combining acute accent). Protocol buffers uses UTF-8 (\"Unicode Transformation Format\") which is a variable-length encoding scheme that represents each code point as a sequence of 1 to 4 single-byte code units. Guidance Character definition TL;DR: In our APIs, \"character\" means \"Unicode code point\". In API documentation (e.g., API reference documents, blog posts, marketing documentation, billing explanations, etc), \"character\" must be defined as a Unicode code point. Length units TL;DR: Set size limits in \"characters\" (as defined above). All string field length limits defined in the API must be measured and enforced in characters as defined above. This means that there is an underlying maximum limit of (4 * characters) bytes, though this limit will only be hit when using exclusively characters that consist of 4 UTF-8 code units (32 bits). If you use a database system (e.g. Spanner) which allows you to define a limit in characters, it is safe to assume that this byte-defined requirement is handled by the underlying storage system. Billing units APIs may use either code points or bytes (using the UTF-8 encoding) as the unit for billing or quota measurement (e.g., Cloud Translation chooses to use characters). If an API does not define this, the assumption is that the unit of billing is characters (e.g., $0.01 per character, not $0.01 per byte). Unique identifiers TL;DR: Unique identifiers should limit to ASCII, generally only letters, numbers, hyphens, and underscores. Additionally, unique identifiers should start with a letter, should end in either a letter or number, and should not have hyphens or underscores that are next to other hyphens or underscores. Strings used as unique identifiers should limit inputs to ASCII characters, typically letters, numbers, hyphens, and underscores ([a-zA-Z][a-zA-Z0-9_-]*). This ensures that there are never accidental collisions due to normalization. If an API decides to allow all valid Unicode characters in unique identifiers, the API must reject any inputs that are not in Normalization Form C. Unique identifiers should use a maximum length of 64 characters, though this limit may be expanded as necessary. 64 characters should be sufficient for most purposes as even UUIDs only require 36 characters. Normalization TL;DR: Unicode values should be stored in Normalization Form C. Values should always be normalized into Normalization Form C. Unique identifiers must always be stored in Normalization Form C (see the next section). Imagine we\u0027re dealing with Spanish input \"estar\u00e9\" (the accented part will be bolded throughout). This text has 6 grapheme clusters, and can be represented by two distinct sequences of Unicode code points: Using 6 code points: U+0065 U+0073 U+0074 U+0061 U+0072 U+00E9 Using 7 code points: U+0065 U+0073 U+0074 U+0061 U+0072 U+0065 U+0301 Further, when encoding to UTF-8, these code points have two different serialized representations: Using 7 code-units (7 bytes): 0x65 0x73 0x74 0x61 0x72 0xC3 0xA9 Using 8 code-units (8 bytes): 0x65 0x73 0x74 0x61 0x72 0x65 0xCC 0x81 To avoid this discrepancy in size (both code units and code points), use Normalization Form C which provides a canonical representation for strings. Uniqueness TL;DR: Unicode values must be normalized to Normalization Form C before checking uniqueness. For the purposes of unique identification (e.g., name, id, or parent), the value must be normalized into Normalization Form C (which happens to be the most compact). Otherwise we may have what is essentially \"the same string\" used to identify two entirely different resources. In our example above, there are two ways of representing what is essentially the same text. This raises the question about whether the two representations should be treated as equivalent or not. In other words, if someone were to use both of those byte sequences in a string field that acts as a unique identifier, would it violate a uniqueness constraint? The W3C recommends using Normalization Form C for all content moving across the internet. It is the most compact normalized form on Unicode text, and avoids most interoperability problems. If we were to treat two Unicode byte sequences as different when they have the same representation in NFC, we\u0027d be required to reply to possible \"Get\" requests with content that is not in normalized form. Since that is definitely unacceptable, we must treat the two as identical by transforming any incoming string data into Normalized Form C or rejecting identifiers not in the normalized form. There is some debate about whether we should view strings as sequences of code points encoded into byte sequences (leading to uniqueness determined based on the byte-representation of said string) or to interpret strings as a higher level abstraction having many different possible byte-representations. The stance taken here is that we already have a field type for handling that: bytes. Fields of type string already express an opinion of the validity of an input (it must be valid UTF-8). As a result, treating two inputs that have identical normalized forms as different due to their underlying byte representation seems to go against the original intent of the string type. This distinction typically doesn\u0027t matter for strings that are opaque to our services (e.g., description or display_name), however when we rely on strings to uniquely identify resources, we are forced to take a stance. Put differently, our goal is to allow someone with text in any encoding (ASCII, UTF-16, UTF-32, etc) to interact with our APIs without a lot of \"gotchas\". References Unicode normalization forms Datastore pricing \"name and value of each property\" doesn\u0027t clarify this. Natural Language pricing uses charges based on UTF-8 code points rather than code units. Text matching and normalization",
    'tags': '',
    'url': '/aip.dev/210',
  },
{
    'title': "Authorization checks",
    'text': "Authorization checks The majority of operations, whether reads or writes, require authorization: permission to do the thing the user is asking to do. Additionally, it is important to be careful how much information is provided to unauthorized users, since leaking information can be a security concern. Guidance Services must check authorization before validating any request, to ensure both a secure API surface and a consistent user experience. An operation may require multiple permissions or preconditions in order to grant authorization. If a request can not pass the authorization check for any reason, the service should error with 403 Forbidden, and the corresponding error message should look like: \"Permission {p} denied on resource {r} (or it might not exist).\" This avoids leaking resource existence. If it is not possible to determine authorization for a resource because the resource does not exist, the service should check authorization to read children on the parent resource, and return 404 Not Found if the authorization check passes. Multiple operations A service could encounter a situation where it has two different operations with two different permissions, either of which would reveal the existence of a resource if called, but a user only has permission to call one of them. In this situation, the service should still only check for authorization applicable to the operation being called, and should not try to \"help out\" by checking for related authorization that would provide permission to reveal existence, because such algorithms are complicated to implement correctly and prone to accidental leaks. For example, posit a scenario where: A resource exists within a given collection that a user is unable to read. The user does have the ability to create other resources, and the collection uses user-specified IDs (meaning that a failure because of a duplicate ID would reveal existance). In this situation, the get or create methods should still only check their permissions when determining what error to return, and not one another\u0027s. Rationale RFC 7231 \u00a76.5.3 states that services are permitted to use 404 Not Found in lieu of 403 Forbidden in situations where the service does not want to divulge existance, whereas this AIP argues for the use of 403 Forbidden instead. We take this position for the following reasons: The practice of \"getting 404 Not Found until you have enough permission to get 403 Forbidden\" is counter-intuitive and increases the difficulty of troubleshooting. A service could ameliorate this by sending information about missing permissions while still using the 404 Not Found status code, but this constitutes a mixed message. While 403 Forbidden is essentially always an error requiring manual action, 404 Not Found is often a valid response that the application can handle (e.g. \"get or create\"); overloading it for permission errors deprives applications of this benefit. RFC 7231 \u00a76.5.4 states that 404 Not Found results are cacheable, but permission errors are not generally cacheable. Sending explicit cache controls on a conditional basis could ameliorate this, but would defeat the purpose. The guidance here is more consistent with most other real-world authorization systems.",
    'tags': '',
    'url': '/aip.dev/211',
  },
]};